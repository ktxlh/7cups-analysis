{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PROFILES = \"/Users/shanglinghsu/7cups-analysis/profiles.csv\"\n",
    "CHAT_RESPONSES = \"/Users/shanglinghsu/7cups-analysis/Chat Questionnaire (Responses) - Form Responses 1.tsv\"\n",
    "EXP_RESPONSES = \"/Users/shanglinghsu/7cups-analysis/Experiment Questionnaire (Responses) - Form Responses 1.tsv\"\n",
    "PARTICIPANTS = \"/Users/shanglinghsu/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/7 Cups Participants.xlsx\"\n",
    "LOG_PATH = \"/Users/shanglinghsu/backup_logs/flask_outputs_20221202\"\n",
    "\n",
    "participants = pd.read_excel(PARTICIPANTS)\n",
    "participants = participants[participants[\"Username\"].notna()]  # Filter mock interivews\n",
    "participants = participants[participants[\"Category Chosen\"].notna()]  # Filter no-show and no responses\n",
    "participants[\"user_id\"] = participants[\"user_id\"].astype(pd.Int16Dtype(), copy=False)\n",
    "participants.reset_index(inplace=True)\n",
    "participants[\"Participant Index\"] = participants.index + 1\n",
    "NUM_PARTICIPANTS = len(participants)\n",
    "\n",
    "profiles = pd.read_csv(PROFILES, header=0, index_col=0)\n",
    "exp_responses = pd.read_csv(EXP_RESPONSES, header=0, sep=\"\\t\")\n",
    "chat_responses = pd.read_csv(CHAT_RESPONSES, header=0, sep=\"\\t\")\n",
    "chats = pd.read_csv(LOG_PATH + \".csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join user tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't join() due to poor support of join() on string dtype\n",
    "def left_join_in_place(left, right, left_on, right_on, rprefix):\n",
    "    for column in right.columns:\n",
    "        if column == right_on: continue\n",
    "        mask, values = [], []\n",
    "        for i, x in enumerate(left[left_on]):\n",
    "            mask = right[right_on] == x\n",
    "            if any(mask):\n",
    "                values.append(right[column][mask].iloc[0])\n",
    "            elif rprefix + column in left.columns:\n",
    "                values.append(left[rprefix + column].loc[i])\n",
    "            else:\n",
    "                values.append(pd.NA)\n",
    "        left[rprefix + column] = values\n",
    "    return left\n",
    "\n",
    "EXP_PREFIX = \"EXP_\"\n",
    "left_join_in_place(participants, profiles, \"Username\", \"Username\", \"\")\n",
    "left_join_in_place(participants, exp_responses, \"user_id\", \"What is the 3-digit User ID for this experiment?\", EXP_PREFIX)\n",
    "\n",
    "# Alias for readability\n",
    "participants[\"Category Confidence\"] = participants[[col for col in participants.columns if \"confident\" in col][0]]\n",
    "\n",
    "participants.to_csv(\"participants_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join chat tables\n",
    "To get from `participants`:\n",
    "- participant user_id\n",
    "- category\n",
    "- order\n",
    "- with tool or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_chat_df = participants[[col for col in participants.columns if (\"id_\" in col) or (\"ategory\" in col) or (\"first\" in col) or (\"user_id\" in col)]]\n",
    "\n",
    "CAT_COL = \"Choose Anxiety\"\n",
    "participants_chat_df[CAT_COL] = participants_chat_df[\"Category Chosen\"].apply(lambda x: 1 if x == \"A\" else 0)\n",
    "\n",
    "left_join_in_place(chats, participants_chat_df, \"chat_id\", \"chat_id_1\", \"\")\n",
    "left_join_in_place(chats, participants_chat_df, \"chat_id\", \"chat_id_2\", \"\")\n",
    "ORDER_COL = \"Order\"\n",
    "chats[ORDER_COL] = [0] * len(chats)\n",
    "chats.loc[chats[\"chat_id_2\"].isna(), ORDER_COL] = 2\n",
    "chats.loc[chats[\"chat_id_1\"].isna(), ORDER_COL] = 1\n",
    "\n",
    "SHOW_COL = \"Show Suggestions\"\n",
    "chats[SHOW_COL] = [0] * len(chats)\n",
    "chats.loc[(chats[ORDER_COL] == 1) & (chats[\"show_suggestion_first\"] > 0.5), SHOW_COL] = 1\n",
    "chats.loc[(chats[ORDER_COL] == 2) & (chats[\"show_suggestion_first\"] < 0.5), SHOW_COL] = 1\n",
    "chats.head(5)\n",
    "\n",
    "chats = chats[list(filter(lambda x: (\"_1\" not in x) and (\"_2\" not in x) and (EXP_PREFIX not in x) and (\"show_suggestion_first\" not in x), chats.columns))]\n",
    "left_join_in_place(chats, chat_responses, \"chat_id\", \"What is the 3-letter Chat ID for this chat?\", \"\")\n",
    "chats = chats.sort_values(by=['datetime'])\n",
    "\n",
    "chats = chats[list(filter(lambda x: ((not any(chats[x].isna())) or x.startswith(\"Any\")), chats.columns))]\n",
    "\n",
    "chats.to_csv(\"chats_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to numeric and binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "BIN_PREFIX = \"BIN_\"\n",
    "NUM_PREFIX = \"NUM_\"\n",
    "\n",
    "def add_convert_column(df, prefix, field, callback):\n",
    "    df[prefix + field] = df[field].apply(callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_convert_column(participants, BIN_PREFIX, \"Counseling Background\", lambda x: 1 if x else 0)\n",
    "add_convert_column(participants, BIN_PREFIX, 'show_suggestion_first', lambda x: 1 if x else 0)\n",
    "participants[\"Counseling Background\"][participants[\"Counseling Background\"].isna()] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_convert_column(participants, NUM_PREFIX, \"Listener Rating\", lambda x: float(x.split()[0]))\n",
    "add_convert_column(participants, NUM_PREFIX, \"Progress Path\", lambda x: int(x.split()[1].replace(\",\", \"\")))\n",
    "add_convert_column(participants, \"OBJ_\", \"Listener Since\", lambda x: datetime.strptime(x, \"%b %d, %Y\"))\n",
    "add_convert_column(participants, NUM_PREFIX, \"Listener Since\", lambda x: (datetime.strptime(x, \"%b %d, %Y\") - datetime.now()).days)\n",
    "\n",
    "NUM_COL_PROFILES = [\n",
    "    \"NUM_Listener Rating\", \n",
    "    \"NUM_Progress Path\", \n",
    "    \"NUM_Listener Since\",\n",
    "    \"Number of Ratings:\",\n",
    "    \"Number of Reviews:\",\n",
    "    \"Cheers\",\n",
    "    \"People Helped\",\n",
    "    \"Chats\",\n",
    "    \"Group Support Chats\",\n",
    "    \"Listener Group Chats\",\n",
    "    \"Forum Posts\",\n",
    "    \"Forum Upvotes\",\n",
    "]\n",
    "participants[\"NUM_Listener Since\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "FREQ_MAP_NUM = {\n",
    "    \"Never\": 0,\n",
    "    \"Very Rarely\": 1,\n",
    "    \"Rarely\": 2,\n",
    "    \"Occasionally\": 3,\n",
    "    \"Frequently\": 4,\n",
    "    \"Very Frequently\": 5,\n",
    "}\n",
    "AGREE_MAP_NUM = {\n",
    "    \"Strongly Disagree\": 0,\n",
    "    \"Disagree\": 1,\n",
    "    \"Undecided\": 2,\n",
    "    \"Agree\": 3,\n",
    "    \"Strongly Agree\": 4,\n",
    "}\n",
    "PROB_MAP_NUM = {\n",
    "    \"Very Probably Not\": 0,\n",
    "    \"Probably Not\": 1,\n",
    "    \"Possibly\": 2,\n",
    "    \"Probably\": 3,\n",
    "    \"Very Probably\": 4,\n",
    "    \"Definitely\": 5,\n",
    "}\n",
    "###############################################################################\n",
    "FREQ_MAP_BIN = {\n",
    "    \"Never\": 0,\n",
    "    \"Very Rarely\": 0,\n",
    "    \"Rarely\": 0,\n",
    "    \"Occasionally\": 1,\n",
    "    \"Frequently\": 1,\n",
    "    \"Very Frequently\": 1,\n",
    "}\n",
    "AGREE_MAP_BIN = {\n",
    "    \"Strongly Disagree\": 0.0,\n",
    "    \"Disagree\": 0.0,\n",
    "    \"Undecided\": 0.5,\n",
    "    \"Agree\": 1.0,\n",
    "    \"Strongly Agree\": 1.0,\n",
    "}\n",
    "PROB_MAP_BIN = {\n",
    "    \"Very Probably Not\": 0,\n",
    "    \"Probably Not\": 0,\n",
    "    \"Possibly\": 0,\n",
    "    \"Probably\": 1,\n",
    "    \"Very Probably\": 1,\n",
    "    \"Definitely\": 1,\n",
    "}\n",
    "###############################################################################\n",
    "FREQ_OPTIONS = [\n",
    "    \"Never\",\n",
    "    \"Very Rarely\",\n",
    "    \"Rarely\",\n",
    "    \"Occasionally\",\n",
    "    \"Frequently\",\n",
    "    \"Very Frequently\",\n",
    "]\n",
    "AGREE_OPTIONS = [\n",
    "    \"Strongly Disagree\",\n",
    "    \"Disagree\",\n",
    "    \"Undecided\",\n",
    "    \"Agree\",\n",
    "    \"Strongly Agree\",\n",
    "]\n",
    "PROB_OPTIONS = [\n",
    "    \"Very Probably Not\",\n",
    "    \"Probably Not\",\n",
    "    \"Possibly\",\n",
    "    \"Probably\",\n",
    "    \"Very Probably\",\n",
    "    \"Definitely\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and \"harmful\" in col]\n",
    "use_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and \"make use of\" in col]\n",
    "freq_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and (\"often\" in col and col not in harmful_cols + use_cols)]\n",
    "agree_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and \"As a whole\" in col]\n",
    "prob_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and \"will you\" in col]\n",
    "checkbox_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and (\"What do you\" in col or \"more when\" in col)]\n",
    "demo_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and (\"age\" in col or \"preferred pronoun(s)\" in col or \"device\" in col)]\n",
    "open_cols = [col for col in participants.columns if col.startswith(EXP_PREFIX) and (col == 'EXP_Any other comments?' or \"like about\" in col or \"helps more\" in col)]\n",
    "confident_cols = [col for col in participants.columns if \"Confidence\" in col]\n",
    "\n",
    "# unused coloumns\n",
    "used_cols = harmful_cols + use_cols + freq_cols + agree_cols + prob_cols + checkbox_cols + demo_cols + open_cols + confident_cols\n",
    "[col for col in participants.columns if col.startswith(EXP_PREFIX) and col not in used_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in freq_cols + use_cols:\n",
    "    add_convert_column(participants, NUM_PREFIX, column, lambda x: FREQ_MAP_NUM[x])\n",
    "    add_convert_column(participants, BIN_PREFIX, column, lambda x: FREQ_MAP_BIN[x])\n",
    "for column in agree_cols:\n",
    "    add_convert_column(participants, NUM_PREFIX, column, lambda x: AGREE_MAP_NUM[x])\n",
    "    add_convert_column(participants, BIN_PREFIX, column, lambda x: AGREE_MAP_BIN[x])\n",
    "for column in prob_cols:\n",
    "    add_convert_column(participants, NUM_PREFIX, column, lambda x: PROB_MAP_NUM[x])\n",
    "    add_convert_column(participants, BIN_PREFIX, column, lambda x: PROB_MAP_BIN[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants['EXP_What is your age?'].describe()[[\"min\", \"max\", \"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(participants['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likert scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reformat_question(question, title):\n",
    "    question = question.replace(\" [-]\", \"\").replace(EXP_PREFIX, \"\").replace(\"...\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    question = question.replace(\"suggested strategies (blue hints)\", \"strategies\")\n",
    "    question = question.replace(\"example responses (white buttons)\", \"examples\")\n",
    "    question = question.replace(title.replace(\"...\", \"\"), \"\")\n",
    "    return question\n",
    "\n",
    "def plot_responses(cols, options, title):\n",
    "    cols = cols[::-1]\n",
    "    count_df = pd.DataFrame(data={}, columns=options)\n",
    "    for option in options:\n",
    "        count_df[option] = (participants[cols] == option).sum()\n",
    "\n",
    "    count_df.plot(\n",
    "        kind='barh', \n",
    "        stacked=True, \n",
    "        cmap=\"RdYlGn\",\n",
    "        width=0.6,\n",
    "        figsize=(5, 0.8 * len(cols) + 0.2)\n",
    "    )\n",
    "    plt.yticks(range(0,len(count_df.index)), list(map(lambda x: reformat_question(x, title).replace(\"?\", \"\"), count_df.index))) # not working dunno why\n",
    "    plt.xlabel('Response Counts')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plot_responses(freq_cols, FREQ_OPTIONS, \"How often did the...\")\n",
    "plot_responses(harmful_cols, FREQ_OPTIONS[::-1], 'How often did the...')\n",
    "plot_responses(agree_cols, AGREE_OPTIONS, \"As a whole, was the tool...\")\n",
    "plot_responses(use_cols, FREQ_OPTIONS, \"If the tool is provided to you, how often do you think you will make use of it?\")\n",
    "plot_responses(prob_cols, PROB_OPTIONS, \"If you can switch the tool on and off as you like, will you switch it on?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "def get_default_option_count(col):\n",
    "    flattened_selections = [b for a in participants[col].apply(lambda x: x.split(\", \")) for b in a]\n",
    "    flattened_selections = list(map(lambda x: \"None of the above\" if \"none\" in x.lower() else x, flattened_selections))\n",
    "    counts = list(Counter(flattened_selections).items())\n",
    "    counts.sort(key=lambda x: x[1])\n",
    "    counts = list(filter(lambda x: x[0] == \"None of the above\" or x[1] > 1, counts))\n",
    "    count_df = pd.DataFrame(data=counts, columns=[\"Selection\", \"Count\"])\n",
    "    return count_df\n",
    "\n",
    "def plot_checkboxes(col, color):\n",
    "    count_df = get_default_option_count(col)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(\n",
    "        width=count_df[\"Count\"],\n",
    "        y=count_df[\"Selection\"],\n",
    "        color=color,\n",
    "    )\n",
    "    for i, x in enumerate(count_df[\"Count\"]):\n",
    "        plt.text(x, i, \" {} ({:.0f}%)\".format(x, x / NUM_PARTICIPANTS * 100))\n",
    "\n",
    "    plt.xlim(0, 15)\n",
    "    plt.xlabel('Response Counts')\n",
    "    plt.title(reformat_question(col, \"\"))\n",
    "\n",
    "plot_checkboxes(\"EXP_What do you like about the tool?\", \"green\")\n",
    "plot_checkboxes(\"EXP_What do you dislike about the tool?\", \"brown\")\n",
    "plot_checkboxes(\"EXP_This tool helps more when...\", \"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in open_cols:\n",
    "    print(col)\n",
    "    default_options = set(get_default_option_count(col)[\"Selection\"].tolist()) if \"comments\" not in col else set()\n",
    "    for row in participants[col]:\n",
    "        open_response = \", \".join(list(filter(lambda x: x not in default_options, row.split(\", \") if type(row) != float else [])))\n",
    "        if len(open_response) == 0: continue\n",
    "        print(open_response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Questionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def compare_chats(df):\n",
    "    x_columns = [SHOW_COL, ORDER_COL, CAT_COL]\n",
    "    y_columns = [x for x in df.columns if \"how\" in x.lower() and x not in x_columns]\n",
    "\n",
    "    data = []\n",
    "    for x_col, y_col in product(x_columns, y_columns):\n",
    "        x_values = list(set(df[x_col].tolist()))\n",
    "        x_values.sort()\n",
    "        if len(x_values) != 2: continue  # control binary variables only\n",
    "        a = df[df[x_col] == x_values[0]][y_col]\n",
    "        b = df[df[x_col] == x_values[1]][y_col]\n",
    "        s, p = mannwhitneyu(a.astype(float), b.astype(float), alternative=\"less\")  # \"less\", \"greater\", \"two-sided\"\n",
    "        data.append((x_col, y_col, s, p))\n",
    "    chat_diff_df = pd.DataFrame(data=data, columns=[\"x\", \"y\", \"Mann-Whitney U statistic\", \"p-value\"])\n",
    "    chat_diff_df = chat_diff_df.sort_values(by=\"p-value\")\n",
    "    return chat_diff_df\n",
    "\n",
    "compare_chats_df = compare_chats(chats[chats[\"Order\"] == 1])\n",
    "compare_chats_df.loc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze per person's difference between chats with and without the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chats\n",
    "x_columns = [SHOW_COL, ORDER_COL, CAT_COL]\n",
    "y_columns = [x for x in df.columns if \"how\" in x.lower() and x not in x_columns]\n",
    "df = df.sort_values(by=[\"user_id\", \"Show Suggestions\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between Listeners and Perceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "from seaborn import heatmap\n",
    "seaborn.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white', 'figure.figsize':(11, 3)})\n",
    "seaborn.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "def draw_heatmap(correlations, title, x_columns):\n",
    "    corr_matrix = pd.DataFrame(data={}, columns=[\"y\",] + [x.replace(NUM_PREFIX, \"\") for x in x_columns])\n",
    "    corr_matrix.set_index(\"y\")\n",
    "    for x, y, r, p in correlations:\n",
    "        if y not in corr_matrix.index:\n",
    "            corr_matrix.loc[y] = [y] + [0.0] * (len(corr_matrix.columns) - 1)\n",
    "        corr_matrix.loc[y, x] = r\n",
    "    \n",
    "    heatmap(corr_matrix[list(filter(lambda x: x != \"y\", corr_matrix.columns))], yticklabels=corr_matrix[\"y\"], xticklabels=corr_matrix.columns[1:]).set(title=title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "def compute_num_exp_correlation(df):\n",
    "    x_columns = NUM_COL_PROFILES + [\"Counseling Background\", \"show_suggestion_first\", \"Category Confidence\", \"Participant Index\"]\n",
    "    y_columns = [\n",
    "        'NUM_EXP_How often did the suggested strategies (blue hints)... [help?]', \n",
    "        'NUM_EXP_How often did the example responses (white buttons)... [help?]', \n",
    "        'NUM_EXP_As a whole, was the tool... [helpful?]', \n",
    "        'NUM_EXP_If the tool is provided to you, how often do you think you will make use of it? [-]', \n",
    "        'NUM_EXP_If you can switch the tool on and off as you like, will you switch it on? [-]',\n",
    "    ]\n",
    "\n",
    "    correlations = []\n",
    "    for x, y in itertools.product(x_columns, y_columns):\n",
    "        r, p = spearmanr(df[x], df[y])\n",
    "        correlations.append((x.replace(NUM_PREFIX, \"\"), y.replace(NUM_PREFIX, \"\").replace(EXP_PREFIX, \"\").replace(\" [-]\", \"\").replace(\"...\", \"\").replace(\"[\", \"\").replace(\"]\", \"\"), r, p))  # remove prefixes for readability\n",
    "\n",
    "    draw_heatmap(correlations, \"Spearman's Correlation between listeners' profile attributes and questionnaire responses converted to numerics\", x_columns)\n",
    "\n",
    "    correlations.sort(key=lambda x: x[-1])\n",
    "    correlation_df = pd.DataFrame(data=correlations, columns=[\"Variable from Listener profile\", \"Variable from questionnaire response\", \"Spearman correlation coefficient\", \"Two-tailed p-value\"])\n",
    "    # correlation_df.to_csv(\"profile-questionnaire-numeric.csv\")\n",
    "    return correlation_df\n",
    "\n",
    "df = compute_num_exp_correlation(participants)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "def compute_bin_exp_correlation(df):\n",
    "    x_columns = NUM_COL_PROFILES + [\"Counseling Background\", \"show_suggestion_first\", \"Category Confidence\", \"Participant Index\"]\n",
    "    y_columns = [\n",
    "        'BIN_EXP_How often did the suggested strategies (blue hints)... [help?]', \n",
    "        'BIN_EXP_How often did the example responses (white buttons)... [help?]', \n",
    "        'BIN_EXP_As a whole, was the tool... [helpful?]', \n",
    "        'BIN_EXP_If the tool is provided to you, how often do you think you will make use of it? [-]', \n",
    "        'BIN_EXP_If you can switch the tool on and off as you like, will you switch it on? [-]',\n",
    "    ]\n",
    "\n",
    "    correlations = []\n",
    "    for x, y in itertools.product(x_columns, y_columns):\n",
    "        r, p = spearmanr(df[x], df[y])\n",
    "        correlations.append((x.replace(NUM_PREFIX, \"\"), y.replace(BIN_PREFIX, \"\").replace(EXP_PREFIX, \"\").replace(\" [-]\", \"\").replace(\"...\", \"\").replace(\"[\", \"\").replace(\"]\", \"\"), r, p))  # remove prefixes for readability\n",
    "\n",
    "    draw_heatmap(correlations, \"Spearman's Correlation between listeners' attributes and questionnaire responses converted to binaries\", x_columns)\n",
    "\n",
    "    correlations.sort(key=lambda x: x[-1])\n",
    "    correlation_df = pd.DataFrame(data=correlations, columns=[\"Variable from Listener profile\", \"Variable from questionnaire response\", \"Spearman correlation coefficient\", \"Two-tailed p-value\"])\n",
    "    # correlation_df.to_csv(\"profile-questionnaire-binary.csv\")\n",
    "    return correlation_df\n",
    "\n",
    "df = compute_bin_exp_correlation(participants)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = participants[[\"NUM_Listener Since\", \"EXP_As a whole, was the tool... [helpful?]\", \"OBJ_Listener Since\", \"Counseling Background\", \"Chats\", \"People Helped\"]].copy()\n",
    "copy[copy[\"Counseling Background\"] < 0.5].sort_values(\"OBJ_Listener Since\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('MI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b75b81fdc2176fa2625b58f5b49ef10110eac4c44972d80176c62f06486cbde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
